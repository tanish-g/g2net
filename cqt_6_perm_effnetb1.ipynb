{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "restricted-hudson",
   "metadata": {
    "papermill": {
     "duration": 0.023362,
     "end_time": "2021-08-04T01:25:11.979040",
     "exception": false,
     "start_time": "2021-08-04T01:25:11.955678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-physiology",
   "metadata": {
    "papermill": {
     "duration": 0.740547,
     "end_time": "2021-08-04T01:25:12.742940",
     "exception": false,
     "start_time": "2021-08-04T01:25:12.002393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-malta",
   "metadata": {
    "papermill": {
     "duration": 1.174264,
     "end_time": "2021-08-04T01:25:13.941421",
     "exception": false,
     "start_time": "2021-08-04T01:25:12.767157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('training_labels.csv')\n",
    "# test = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "def get_train_file_path(image_id):\n",
    "    return \"g2net_train/{}/{}/{}/{}.npy\".format(\n",
    "        image_id[0], image_id[1], image_id[2], image_id)\n",
    "\n",
    "def get_test_file_path(image_id):\n",
    "    return \"g2net_test/{}/{}/{}/{}.npy\".format(\n",
    "        image_id[0], image_id[1], image_id[2], image_id)\n",
    "\n",
    "train['file_path'] = train['id'].apply(get_train_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1603b9a8-f77c-4e75-a891-b1c5d6d78970",
   "metadata": {},
   "source": [
    "# GPU_AUGMENTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1340275-07f4-4799-87e4-cbfffaccaf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kornia\n",
    "import kornia.augmentation as K\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from kornia.geometry.transform import Resize\n",
    "\n",
    "\n",
    "class RandomRoll(K.base.IntensityAugmentationBase2D):\n",
    "    def __init__(\n",
    "        self, dims=[-2, -1], direction=[1, 1], max_shift_pct=[1.0, 1.0], p=0.5, keepdim=True\n",
    "    ):\n",
    "        super().__init__(p=p, keepdim=keepdim)\n",
    "        self.direction = torch.tensor(direction if isinstance(direction, list) else [direction])\n",
    "        self.max_shift_pct = torch.tensor(\n",
    "            max_shift_pct if isinstance(max_shift_pct, list) else [max_shift_pct]\n",
    "        )\n",
    "        self.dims = tuple(dims if isinstance(dims, list) else [dims])\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.__class__.__name__ + f\"({super().__repr__()})\"\n",
    "\n",
    "    def generate_parameters(self, input_shape: torch.Size):\n",
    "        shifts = torch.rand(input_shape[0], len(self.dims)) * self.max_shift_pct * self.direction\n",
    "        input_shape = torch.take(torch.tensor(input_shape), torch.tensor(self.dims))[None, :]\n",
    "        shifts = (shifts * input_shape).int()\n",
    "        return dict(shifts=shifts)\n",
    "\n",
    "    def apply_transform(self, input, params, transform=None):\n",
    "        input = torch.unbind(input, dim=0)\n",
    "        shifts = torch.unbind(params[\"shifts\"], dim=0)\n",
    "        input = torch.stack(\n",
    "            [torch.roll(x, tuple(s.tolist()), dims=self.dims) for x, s in zip(input, shifts)],\n",
    "            dim=0,\n",
    "        )\n",
    "        return input\n",
    "\n",
    "\n",
    "class RandomRollH(RandomRoll):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(dims=-2, direction=1, max_shift_pct=1.0, **kwargs)\n",
    "\n",
    "\n",
    "class RandomRollW(RandomRoll):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(dims=-1, direction=1, max_shift_pct=1.0, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2681b2-6a62-471b-b1e1-79c5656a94ad",
   "metadata": {},
   "source": [
    "# CWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef5bd9-086e-474e-9887-61eb2cdc0426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW ITS TIME TO CWT !!!!\n",
    "# From https://github.com/tomrunia/PyTorchWavelets/blob/master/wavelets_pytorch/wavelets.py\n",
    "\n",
    "class Morlet(object):\n",
    "    def __init__(self, w0=6):\n",
    "        \"\"\"w0 is the nondimensional frequency constant. If this is\n",
    "        set too low then the wavelet does not sample very well: a\n",
    "        value over 5 should be ok; Terrence and Compo set it to 6.\n",
    "        \"\"\"\n",
    "        self.w0 = w0\n",
    "        if w0 == 6:\n",
    "            # value of C_d from TC98\n",
    "            self.C_d = 0.776\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.time(*args, **kwargs)\n",
    "\n",
    "    def time(self, t, s=1.0, complete=True):\n",
    "        \"\"\"\n",
    "        Complex Morlet wavelet, centred at zero.\n",
    "        Parameters\n",
    "        ----------\n",
    "        t : float\n",
    "            Time. If s is not specified, this can be used as the\n",
    "            non-dimensional time t/s.\n",
    "        s : float\n",
    "            Scaling factor. Default is 1.\n",
    "        complete : bool\n",
    "            Whether to use the complete or the standard version.\n",
    "        Returns\n",
    "        -------\n",
    "        out : complex\n",
    "            Value of the Morlet wavelet at the given time\n",
    "        See Also\n",
    "        --------\n",
    "        scipy.signal.gausspulse\n",
    "        Notes\n",
    "        -----\n",
    "        The standard version::\n",
    "            pi**-0.25 * exp(1j*w*x) * exp(-0.5*(x**2))\n",
    "        This commonly used wavelet is often referred to simply as the\n",
    "        Morlet wavelet.  Note that this simplified version can cause\n",
    "        admissibility problems at low values of `w`.\n",
    "        The complete version::\n",
    "            pi**-0.25 * (exp(1j*w*x) - exp(-0.5*(w**2))) * exp(-0.5*(x**2))\n",
    "        The complete version of the Morlet wavelet, with a correction\n",
    "        term to improve admissibility. For `w` greater than 5, the\n",
    "        correction term is negligible.\n",
    "        Note that the energy of the return wavelet is not normalised\n",
    "        according to `s`.\n",
    "        The fundamental frequency of this wavelet in Hz is given\n",
    "        by ``f = 2*s*w*r / M`` where r is the sampling rate.\n",
    "        \"\"\"\n",
    "        w = self.w0\n",
    "\n",
    "        x = t / s\n",
    "\n",
    "        output = np.exp(1j * w * x)\n",
    "\n",
    "        if complete:\n",
    "            output -= np.exp(-0.5 * (w ** 2))\n",
    "\n",
    "        output *= np.exp(-0.5 * (x ** 2)) * np.pi ** (-0.25)\n",
    "\n",
    "        return output\n",
    "\n",
    "    # Fourier wavelengths\n",
    "    def fourier_period(self, s):\n",
    "        \"\"\"Equivalent Fourier period of Morlet\"\"\"\n",
    "        return 4 * np.pi * s / (self.w0 + (2 + self.w0 ** 2) ** 0.5)\n",
    "\n",
    "    def scale_from_period(self, period):\n",
    "        \"\"\"\n",
    "        Compute the scale from the fourier period.\n",
    "        Returns the scale\n",
    "        \"\"\"\n",
    "        # Solve 4 * np.pi * scale / (w0 + (2 + w0 ** 2) ** .5)\n",
    "        #  for s to obtain this formula\n",
    "        coeff = np.sqrt(self.w0 * self.w0 + 2)\n",
    "        return (period * (coeff + self.w0)) / (4.0 * np.pi)\n",
    "\n",
    "    # Frequency representation\n",
    "    def frequency(self, w, s=1.0):\n",
    "        \"\"\"Frequency representation of Morlet.\n",
    "        Parameters\n",
    "        ----------\n",
    "        w : float\n",
    "            Angular frequency. If `s` is not specified, i.e. set to 1,\n",
    "            this can be used as the non-dimensional angular\n",
    "            frequency w * s.\n",
    "        s : float\n",
    "            Scaling factor. Default is 1.\n",
    "        Returns\n",
    "        -------\n",
    "        out : complex\n",
    "            Value of the Morlet wavelet at the given frequency\n",
    "        \"\"\"\n",
    "        x = w * s\n",
    "        # Heaviside mock\n",
    "        Hw = np.array(w)\n",
    "        Hw[w <= 0] = 0\n",
    "        Hw[w > 0] = 1\n",
    "        return np.pi ** -0.25 * Hw * np.exp((-((x - self.w0) ** 2)) / 2)\n",
    "\n",
    "    def coi(self, s):\n",
    "        \"\"\"The e folding time for the autocorrelation of wavelet\n",
    "        power at each scale, i.e. the timescale over which an edge\n",
    "        effect decays by a factor of 1/e^2.\n",
    "        This can be worked out analytically by solving\n",
    "            |Y_0(T)|^2 / |Y_0(0)|^2 = 1 / e^2\n",
    "        \"\"\"\n",
    "        return 2 ** 0.5 * s\n",
    "\n",
    "\n",
    "class CWT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dj=0.0625,\n",
    "        dt=1 / 2048,\n",
    "        fmin: int = 20,\n",
    "        fmax: int = 500,\n",
    "        output_format=\"Magnitude\",\n",
    "        trainable=False,\n",
    "        padding=0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.wavelet = Morlet()\n",
    "\n",
    "        self.dt = dt\n",
    "        self.dj = dj\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax\n",
    "        self.output_format = output_format\n",
    "        self.trainable = trainable  # TODO make kernel a trainable parameter\n",
    "        self.stride = (1, 1)  # Strides > 1 not yet supported\n",
    "        self.padding = padding\n",
    "\n",
    "        self.signal_length = 4096  # x.shape[-1]\n",
    "        self.channels = 3  # x.shape[-2]\n",
    "        \n",
    "        scale_minimum = self.compute_minimum_scale()\n",
    "        scales = self.compute_optimal_scales(scale_minimum)\n",
    "        kernel = self.build_wavelet_bank(scales)\n",
    "    \n",
    "        if kernel.is_complex():\n",
    "            self.register_buffer(\"kernel_real\", kernel.real, persistent=False)\n",
    "            self.register_buffer(\"kernel_imag\", kernel.imag, persistent=False)\n",
    "        else:\n",
    "            self.register_buffer(\"kernel\", kernel, persistent=False)\n",
    "\n",
    "    def compute_optimal_scales(self, scale_minimum):\n",
    "        \"\"\"\n",
    "        Determines the optimal scale distribution (see. Torrence & Combo, Eq. 9-10).\n",
    "        :return: np.ndarray, collection of scales\n",
    "        \"\"\"\n",
    "        if self.signal_length is None:\n",
    "            raise ValueError(\"Please specify signal_length before computing optimal scales.\")\n",
    "        J = int((1 / self.dj) * np.log2(self.signal_length * self.dt / scale_minimum))\n",
    "        scales = scale_minimum * 2 ** (self.dj * np.arange(0, J + 1))\n",
    "\n",
    "        # Remove high and low frequencies\n",
    "        frequencies = np.array([1 / self.wavelet.fourier_period(s) for s in scales])\n",
    "        if self.fmin:\n",
    "            frequencies = frequencies[frequencies >= self.fmin]\n",
    "            scales = scales[slice(0, len(frequencies))]\n",
    "        if self.fmax:\n",
    "            frequencies = frequencies[frequencies <= self.fmax]\n",
    "            scales = scales[slice(len(scales) - len(frequencies), len(scales))]\n",
    "        return scales\n",
    "\n",
    "    def compute_minimum_scale(self):\n",
    "        \"\"\"\n",
    "        Choose s0 so that the equivalent Fourier period is 2 * dt.\n",
    "        See Torrence & Combo Sections 3f and 3h.\n",
    "        :return: float, minimum scale level\n",
    "        \"\"\"\n",
    "\n",
    "        def func_to_solve(s):\n",
    "            return self.wavelet.fourier_period(s) - 2 * self.dt\n",
    "\n",
    "        return optimize.fsolve(func_to_solve, 1)[0]\n",
    "\n",
    "    def build_filters(self, scales):\n",
    "        filters = []\n",
    "        for scale_idx, scale in enumerate(scales):\n",
    "            # Number of points needed to capture wavelet\n",
    "            M = 10 * scale / self.dt\n",
    "            # Times to use, centred at zero\n",
    "            t = torch.arange((-M + 1) / 2.0, (M + 1) / 2.0) * self.dt\n",
    "            if len(t) % 2 == 0:\n",
    "                t = t[0:-1]  # requires odd filter size\n",
    "            # Sample wavelet and normalise\n",
    "            norm = (self.dt / scale) ** 0.5\n",
    "            filter_ = norm * self.wavelet(t, scale)\n",
    "            filters.append(torch.conj(torch.flip(filter_, [-1])))\n",
    "\n",
    "        filters = self.pad_filters(filters)\n",
    "        return filters\n",
    "\n",
    "    def pad_filters(self, filters):\n",
    "        filter_len = filters[-1].shape[0]\n",
    "        padded_filters = []\n",
    "\n",
    "        for f in filters:\n",
    "            pad = (filter_len - f.shape[0]) // 2\n",
    "            padded_filters.append(nn.functional.pad(f, (pad, pad)))\n",
    "\n",
    "        return padded_filters\n",
    "\n",
    "    def build_wavelet_bank(self, scales):\n",
    "        \"\"\"This function builds a 2D wavelet filter using wavelets at different scales\n",
    "\n",
    "        Returns:\n",
    "            tensor: Tensor of shape (num_widths, 1, channels, filter_len)\n",
    "        \"\"\"\n",
    "\n",
    "        filters = self.build_filters(scales)\n",
    "        wavelet_bank = torch.stack(filters)\n",
    "        wavelet_bank = wavelet_bank.view(wavelet_bank.shape[0], 1, 1, wavelet_bank.shape[1])\n",
    "\n",
    "        return wavelet_bank\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Compute CWT arrays from a batch of multi-channel inputs\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): Tensor of shape (batch_size, channels, time)\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Tensor of shape (batch_size, channels, widths, time)\n",
    "        \"\"\"\n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        if not hasattr(self, 'kernel'):\n",
    "            output_real = nn.functional.conv2d(\n",
    "                x, self.kernel_real, padding=self.padding, stride=self.stride\n",
    "            )\n",
    "            output_imag = nn.functional.conv2d(\n",
    "                x, self.kernel_imag, padding=self.padding, stride=self.stride\n",
    "            )\n",
    "            output_real = torch.transpose(output_real, 1, 2)\n",
    "            output_imag = torch.transpose(output_imag, 1, 2)\n",
    "\n",
    "            if self.output_format == \"Magnitude\":\n",
    "                return torch.sqrt(output_real ** 2 + output_imag ** 2).contiguous()\n",
    "            else:\n",
    "                return torch.stack([output_real, output_imag], -1).contiguous()\n",
    "\n",
    "        else:\n",
    "\n",
    "            output = nn.functional.conv2d(x, self.kernel, padding=self.padding, stride=self.stride)\n",
    "            return torch.transpose(output, 1, 2).contiguous()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-kansas",
   "metadata": {
    "papermill": {
     "duration": 0.035693,
     "end_time": "2021-08-04T01:25:16.603286",
     "exception": false,
     "start_time": "2021-08-04T01:25:16.567593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-effect",
   "metadata": {
    "papermill": {
     "duration": 0.04513,
     "end_time": "2021-08-04T01:25:16.683443",
     "exception": false,
     "start_time": "2021-08-04T01:25:16.638313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    num_workers=16\n",
    "    model_name='tf_efficientnet_b1_ns'\n",
    "    epochs=8\n",
    "    lr=1e-4   \n",
    "    min_lr=1e-6\n",
    "    batch_size=64     \n",
    "    weight_decay=1e-6  \n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    qtransform_params={\"sr\": 2048, \"fmin\":24, \"fmax\":364, \"hop_length\": 6 , \"bins_per_octave\": 8}\n",
    "    seed=42\n",
    "    save_dir=''\n",
    "    target_size=1\n",
    "    target_col='target'\n",
    "    n_fold=5\n",
    "    trn_fold=[0,1,2,3,4]\n",
    "    train=True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-suicide",
   "metadata": {
    "papermill": {
     "duration": 0.034417,
     "end_time": "2021-08-04T01:25:16.751155",
     "exception": false,
     "start_time": "2021-08-04T01:25:16.716738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436332b-64d7-407a-b754-d33e191d9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nnAudio.Spectrogram import CQT1992v2\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torch.fft import fft, ifft\n",
    "\n",
    "import scipy.signal as signal\n",
    "import scipy.optimize as optimize\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import timm\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-simpson",
   "metadata": {
    "papermill": {
     "duration": 0.034462,
     "end_time": "2021-08-04T01:25:16.451810",
     "exception": false,
     "start_time": "2021-08-04T01:25:16.417348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10482f-ec7a-4d3d-b57d-c9c768cf0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "OUTPUT_DIR = CFG.save_dir\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c2784f-0754-4376-a801-3d219694ff0b",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133b1715-bada-44cc-93db-535f24f9f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW=signal.tukey(4096, 0.25)[None,:]\n",
    "LF=24 # definitely must try lower values like 20 24 28 etc...\n",
    "HF=364 # i dont think that higher than this is relevant...\n",
    "def ts_window(ts): return ts * WINDOW\n",
    "\n",
    "def ts_whiten(ts, lf=LF, hf=HF, order=4):\n",
    "    sos = signal.butter(order, [lf, hf], btype=\"bandpass\", output=\"sos\", fs=2048)\n",
    "    normalization = np.sqrt((hf - lf) / (2048 / 2))\n",
    "    return signal.sosfiltfilt(sos, ts) / normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-performance",
   "metadata": {
    "papermill": {
     "duration": 0.051924,
     "end_time": "2021-08-04T01:25:27.152541",
     "exception": false,
     "start_time": "2021-08-04T01:25:27.100617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-dakota",
   "metadata": {
    "papermill": {
     "duration": 0.078664,
     "end_time": "2021-08-04T01:25:27.284121",
     "exception": false,
     "start_time": "2021-08-04T01:25:27.205457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    score = roc_auc_score(y_true, y_pred)\n",
    "    return score\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-complex",
   "metadata": {
    "papermill": {
     "duration": 0.055844,
     "end_time": "2021-08-04T01:25:27.390591",
     "exception": false,
     "start_time": "2021-08-04T01:25:27.334747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-component",
   "metadata": {
    "papermill": {
     "duration": 0.382316,
     "end_time": "2021-08-04T01:25:27.823267",
     "exception": false,
     "start_time": "2021-08-04T01:25:27.440951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train = train.sample(frac=0.1,random_state=42).reset_index(drop=True)\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_col])):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "display(train.groupby(['fold', 'target']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-expense",
   "metadata": {
    "papermill": {
     "duration": 0.033889,
     "end_time": "2021-08-04T01:25:27.897251",
     "exception": false,
     "start_time": "2021-08-04T01:25:27.863362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-particular",
   "metadata": {
    "papermill": {
     "duration": 0.045394,
     "end_time": "2021-08-04T01:25:27.976623",
     "exception": false,
     "start_time": "2021-08-04T01:25:27.931229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df,mode,transform=None):\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        self.file_names = df['file_path'].values\n",
    "        self.labels = df[CFG.target_col].values\n",
    "        self.det = torch.tensor(np.load('det.npy'))\n",
    "        self.transform = CQT1992v2(**CFG.qtransform_params)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_names[idx]\n",
    "        waves = np.load(file_path)\n",
    "        waves = ts_window(waves)\n",
    "        waves = ts_whiten(waves)\n",
    "        waves = torch.tensor(waves).float()\n",
    "        label = torch.tensor(self.labels[idx]).float()\n",
    "        return waves,label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-beaver",
   "metadata": {
    "papermill": {
     "duration": 0.045247,
     "end_time": "2021-08-04T01:25:29.187985",
     "exception": false,
     "start_time": "2021-08-04T01:25:29.142738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b4726-208e-42d4-8ee3-29adafb3f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# MODEL\n",
    "# ====================================================\n",
    "from torch.fft import fft, ifft\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.det = torch.tensor(np.load('det.npy')).to(device)\n",
    "        self.batchnorm = nn.BatchNorm2d(6)\n",
    "        self.model = timm.create_model(self.cfg.model_name, pretrained=pretrained, in_chans=6)\n",
    "        self.n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(self.n_features, self.cfg.target_size)\n",
    "        self.transform = CQT1992v2(**cfg.qtransform_params)\n",
    "        \n",
    "    def forward(self, waves):\n",
    "        waves = fft(waves)\n",
    "        waves = waves/self.det\n",
    "        waves = torch.fft.ifft(waves).real\n",
    "        waves = waves.float()\n",
    "        \n",
    "        waves1 = torch.cat([waves[:,0,:],waves[:,1,:],waves[:,2,:]],axis=1)\n",
    "        waves2 = torch.cat([waves[:,0,:],waves[:,2,:],waves[:,1,:]],axis=1)\n",
    "        waves3 = torch.cat([waves[:,1,:],waves[:,0,:],waves[:,2,:]],axis=1)\n",
    "        waves4 = torch.cat([waves[:,1,:],waves[:,2,:],waves[:,0,:]],axis=1)\n",
    "        waves5 = torch.cat([waves[:,2,:],waves[:,0,:],waves[:,1,:]],axis=1)\n",
    "        waves6 = torch.cat([waves[:,2,:],waves[:,1,:],waves[:,0,:]],axis=1)\n",
    "        \n",
    "        image1 = self.transform(waves1)\n",
    "        image2 = self.transform(waves2)\n",
    "        image3 = self.transform(waves3)\n",
    "        image4 = self.transform(waves4)\n",
    "        image5 = self.transform(waves5)\n",
    "        image6 = self.transform(waves6)\n",
    "        \n",
    "        image = torch.stack((image1,image2,image3,image4,image5,image6),axis=1)\n",
    "        image = self.batchnorm(image)\n",
    "        output = self.model(image)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-rings",
   "metadata": {
    "papermill": {
     "duration": 0.071264,
     "end_time": "2021-08-04T01:25:29.451162",
     "exception": false,
     "start_time": "2021-08-04T01:25:29.379898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-philadelphia",
   "metadata": {
    "papermill": {
     "duration": 0.112331,
     "end_time": "2021-08-04T01:25:29.638305",
     "exception": false,
     "start_time": "2021-08-04T01:25:29.525974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    losses = AverageMeter()\n",
    "    model.train()\n",
    "    tk1 = tqdm(enumerate(train_loader),total=len(train_loader))\n",
    "    for step, (images, labels) in tk1:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        y_preds = model(images,'train')\n",
    "        loss = criterion(y_preds.view(-1), labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        tk1.set_postfix(loss=losses.avg)\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    tk2 = tqdm(enumerate(valid_loader),total=len(valid_loader))\n",
    "    for step, (images, labels) in tk2:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images,'valid')\n",
    "        loss = criterion(y_preds.view(-1), labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "        tk2.set_postfix(loss=losses.avg)\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-physiology",
   "metadata": {
    "papermill": {
     "duration": 0.052219,
     "end_time": "2021-08-04T01:25:29.904968",
     "exception": false,
     "start_time": "2021-08-04T01:25:29.852749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-truck",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.075124,
     "end_time": "2021-08-04T01:25:30.031874",
     "exception": false,
     "start_time": "2021-08-04T01:25:29.956750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold):\n",
    "    \n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "\n",
    "    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n",
    "    valid_labels = valid_folds[CFG.target_col].values\n",
    "\n",
    "    train_dataset = TrainDataset(train_folds,mode='train',transform=None)\n",
    "    valid_dataset = TrainDataset(valid_folds,mode='val', transform=None)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=True, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                              batch_size=CFG.batch_size * 2, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG, pretrained=True)\n",
    "    model.to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr=1e-3,epochs=CFG.epochs,steps_per_epoch=len(train_loader),pct_start=0.05,div_factor=100,final_div_factor=100)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_score = 0.\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch,scheduler,device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(), \n",
    "                        'preds': preds},\n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n",
    "        \n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(), \n",
    "                        'preds': preds},\n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth')\n",
    "    \n",
    "    valid_folds['preds'] = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth', \n",
    "                                      map_location=torch.device('cpu'))['preds']\n",
    "\n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-chase",
   "metadata": {
    "papermill": {
     "duration": 0.073141,
     "end_time": "2021-08-04T01:25:30.156241",
     "exception": false,
     "start_time": "2021-08-04T01:25:30.083100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Prepare: 1.train \n",
    "    \"\"\"\n",
    "    def get_result(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df[CFG.target_col].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.4f}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        # train \n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(train, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        # CV result\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        # save result\n",
    "        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ce1b41-8cac-4e8c-8a1b-9019f5f6f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-newark",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 25805.563027,
     "end_time": "2021-08-04T08:35:35.784865",
     "exception": false,
     "start_time": "2021-08-04T01:25:30.221838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25873.904478,
   "end_time": "2021-08-04T08:35:38.687604",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-04T01:24:24.783126",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0dbcc4217a054bf59536c68c137aea9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0f6df99cb9b44c7e93bc2404173fbac8",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_0dc3c559d45a4b138f9da0c94f0ae0b4",
       "value": " 0.30MB of 0.30MB uploaded (0.00MB deduped)\r"
      }
     },
     "0dc3c559d45a4b138f9da0c94f0ae0b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0f6df99cb9b44c7e93bc2404173fbac8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "149fb7a2fa514298b54c12708c047702": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "61a74751fbe346ceb5a88f4c2efe9b78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0dbcc4217a054bf59536c68c137aea9f",
        "IPY_MODEL_9622698a24254ef5921f90daa4434078"
       ],
       "layout": "IPY_MODEL_149fb7a2fa514298b54c12708c047702"
      }
     },
     "9622698a24254ef5921f90daa4434078": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ac8e1db3c0714735b4260bf11029eed4",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e468bad39eed4c61b1f3fc42412b3f39",
       "value": 1
      }
     },
     "ac8e1db3c0714735b4260bf11029eed4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e468bad39eed4c61b1f3fc42412b3f39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
